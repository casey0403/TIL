
### 카프카 컨슈머 중복처리 원인과 방지

1. offset commit
    1. default 자동 컴밋
    2. 비즈니스 로직(저장과 같은) 처리 후 수동 커밋 & RDB offset 저장
    3. 하지만 이 경우에도 중복을 완전히 방지할 수 없음
2. max.poll.interval.ms
    1. max.poll.interval.ms 설정시간에 poll() 메소드가 호출되지 않아 리밸런스가 발생하는 경우
    2. consumer group 에서 해당 컨슈머 제외시키고 리밸런싱이 일어나고
    3. 해당 오프셋은 재처리가 일어날 수 있음
    4. max.poll.interval.ms 설정시간을 늘려야함. 
    5. 비즈니스 로직의 처리 시간을 확인한 후 커스텀
3. max.poll.records 
    1. default Batch Read 를 수행.
    2. max.poll.records 값을 작게 설정하여 리밸런싱 시간을 단축시키거나, 리밸런싱 발생 가능성을 감소
    3. 혹은 max.poll.records=1으로 설정하여 단일 메시지 단위로 커밋시도
4. Ack Mode
    1. default BATCH (in Spring Kafka)
    2. MANUAL 등의 모드를 적용하여 중복 Consume 가능성 감소
5. 중복 메시지 처리 방지를 위한 멱등성 처리 로직을 작성

